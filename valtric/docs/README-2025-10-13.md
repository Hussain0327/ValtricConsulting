# 2025-10-13 Daily Readme

## What Changed Today
- Docker `valtric-db` container confirmed healthy and reachable (`docker ps`, `docker-compose exec db pg_isready`).
- Generated Alembic migration `2c844178c916_init_tables.py` covering `deals`, `documents`, `chunks`, `embeddings`, `analyses`, and `lineage_events` (`migrations/versions/2c844178c916_init_tables.py:1`).
- Fixed the autogen migration to import `Vector` from `pgvector` so upgrades run (`migrations/versions/2c844178c916_init_tables.py:11`).
- Applied `alembic upgrade head` to materialize the schema in Postgres.
- Booted the FastAPI app via `uvicorn app.main:app --reload --port 8000` and smoke-tested:
  - `GET /health` → 200 (`app/routers/health.py:6`)
  - `POST /deals` → persisted `Deal` rows (`app/routers/deals.py:10`)
  - `POST /analyze` → streams valuation JSON from the new DeepSeek + GPT-5 pipeline (`app/routers/analyze.py:13`)
- Added adaptive routing so GPT-5 Nano handles "easy" questions with minimal reasoning, while DeepSeek escalates only when heuristics mark the query as "hard" (`app/services/consultant.py:20`).
- Wired DeepSeek V3.1 Hybrid (low reasoning) and GPT-5 Nano (high reasoning) into the valuation flow, plus OpenAI embeddings and Cohere/BGE rerank service scaffolding (`app/services/consultant.py:13`, `app/services/embed.py:15`, `app/services/rerank.py:15`).
- Built a Supabase ingestion + sync path: `/foundry/ingest` persists deals/chunks to both Postgres and Supabase, retrieval prefers Supabase's `match_chunks` RPC, and `scripts/sync_supabase.py` can backfill existing rows (`app/routers/foundry.py:1`, `app/services/foundry/pipeline.py:1`, `app/services/retrieve.py:1`, `scripts/sync_supabase.py:1`).

## Current State
- Database models align with the new migration (`app/models.py:1`), including pgvector embeddings and lineage capture.
- Database bootstrap ensures the `vector` extension exists before serving (`app/db.py:5`).
- Settings load CORS/database config from `.env` with JSON-aware parsing (`app/settings.py:1`).
- API surface:
  - Health check at `/health`.
  - Deal creation via `/deals` and lookup via `/deals/{deal_id}`.
  - Valuation analysis stub at `/analyze`.
- Support scripts: `scripts/seed.py` can populate sample deals for testing.
- Frontend, RAG pipeline, and AI workflows are mostly placeholders (`frontend/src`, `app/services/*`, `app/rag/*`).
- Query classification heuristics log complexity and timing to help tune latency (`app/services/consultant.py:20`).
- `/analyze` now runs a two-stage LLM pipeline with DeepSeek triage and GPT-5 Nano final memo; falls back to heuristics if either provider errors (`app/services/consultant.py:13`).
- Supabase credentials live in `.env` (service-role + anon); `.env.example` documents the required keys (`valtric/backend/.env.example:1`).

## Model Stack Decisions
- **Primary reasoning (fast path)**: DeepSeek V3.1 Hybrid with `reasoning.effort="low"` for quick valuations, doc triage, and lightweight tool use. Needs `DEEPSEEK_API_KEY` plus optional `DEEPSEEK_BASE_URL` if you self-host.
- **Secondary reasoning (deep dive)**: GPT-5 Nano with `reasoning.effort="high"` as a validation or escalation step when answers need more rigor. Uses OpenAI Responses API (`OPENAI_API_KEY`, optional `OPENAI_BASE_URL`).
- **Embeddings**: `text-embedding-3-large` (OpenAI) as the default embedding model for chunk vectors and semantic search.
- **Rerank**: Cohere Rerank v3 (`rerank-english-v3.0`) when `COHERE_API_KEY` is available; otherwise fall back to a local `bge-reranker-large` runner wired through the retrieval service.
- **Config follow-up**: Extend `app/settings.py` to expose `primary_model`, `secondary_model`, `embedding_model`, `rerank_provider`, and corresponding API credentials so deployments can toggle providers without code edits.

## What To Tackle Tomorrow
- **Data seeding & migrations**
  - Decide whether to keep the sample deal inserted today; if not, `DELETE FROM deals` or reset the DB.
  - Capture a baseline SQL dump after running the new migration.
- **Backend hardening**
  - Add validation/tests around deal creation & analysis (`tests/` is empty).
  - Implement GET `/deals` list endpoint if needed for the Foundry UI.
  - Verify Supabase RPC (`match_chunks`) and add automated tests/mocks for retrieval fallback logic.
  - Backfill integration tests/mocks for the new LLM, embedding, and rerank services to keep future refactors safe.
  - Surface richer telemetry (latency, provider failures) via `structlog` once logging utilities are in place.
  - Plug in Supabase vector store + rerank so the "hard" classifier can leverage actual RAG hits instead of heuristics.
- **Observability & Ops**
  - Add logging around long-running tasks (`app/utils/logging.py`) once services flesh out.
  - Document the docker/uvicorn workflow in the main README.

## AI Agent Roadmap
- **Document ingestion**: implement upload → chunk → embed pipeline (`app/services/chunk.py`, `app/services/embed.py`) and persist to `documents`, `chunks`, `embeddings`.
- **Vector search**: finalize Supabase `match_chunks` RPC + local fallback tests so retrieval returns production-ready context.
- **RAG assembly**: fill in `app/rag/pack.py` and `app/services/rerank.py` to score and package chunks for the LLM, wiring to Supabase's pgvector API once credentials are ready.
- **LLM integration**: refine prompt templates + error handling for the new DeepSeek → GPT-5 handoff, and add persistence of intermediate triage notes if we need them later.
- **Lineage tracking**: populate `lineage_events` when the agent assembles context so `/analyze` responses can cite sources.

## Foundry Tool (Frontend) TODO
- Bootstrap React app (`frontend/src/main.tsx`, `frontend/src/App.tsx`) with routing for Dashboard & Deal detail pages.
- Build UI components (`frontend/src/components/*`) to:
  - Upload deal docs and show ingestion status.
  - Display valuation output, comps, and risk flags.
  - Stream analysis progress (hook up `src/lib/sse.ts` when backend supports SSE).
- Connect to backend API: create fetch hooks in `src/lib/api.ts` to call `/deals`, `/analyze`, and future ingestion endpoints.
- Add state management (Zustand/Redux) if the Foundry workflow needs cross-page coordination.
- Style system: decide on design tokens / shadcn integration (`shadcn.config.ts`) once components are concrete.

## Quick Runbook
```bash
cd ~/Downloads/ValtricConsulting/valtric/backend
source .venv/bin/activate
pip install -r requirements.txt  # first run only
alembic upgrade head
uvicorn app.main:app --reload --port 8000
```

Smoke tests:
```bash
curl http://127.0.0.1:8000/health
curl -X POST http://127.0.0.1:8000/deals \
  -H "Content-Type: application/json" \
  -d '{"name":"Example","industry":"SaaS","price":1200000,"ebitda":200000,"currency":"USD"}'
curl -X POST http://127.0.0.1:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"deal_id":1,"question":"Is this valuation reasonable?"}'
```

Supabase bootstrap:
```bash
# 1. Apply supabase.sql (ensures tables/extensions exist).
# 2. Create the match_chunks RPC:
#    see scripts/supabase.sql or docs for the function definition.
# 3. Run the one-time sync from local Postgres → Supabase
cd ~/Downloads/ValtricConsulting/valtric/backend
source .venv/bin/activate
python scripts/sync_supabase.py
```

## Outstanding Questions
- Which embedding provider and model should power `app/services/embed.py`?
- What output format and interactivity does the Foundry UI need (static report vs. chat)?
- Do we need role-based auth or org scoping before multi-tenant data ingestion?

• - Added the daily progress log at valtric/docs/README-2025-10-13.md with
    today’s completed work, backend status, AI-agent roadmap, Foundry UI
    TODOs, and runbook/questions for tomorrow.
  - Documented the migration fix (valtric/backend/migrations/
    versions/2c844178c916_init_tables.py:1, :11), current API behavior
    (valtric/backend/app/routers/*.py), service stubs (valtric/backend/app/
    services/*.py), and the React placeholders (valtric/frontend/src).
  - Run the steps in the new log tomorrow to pick up where you left off; once
    you decide on embedding/LLM providers, we can flesh out the ingestion and
    Foundry workflows next.
  
  # codex resume 0199dfcc-bdff-7683-81de-a87e4c25adc5
